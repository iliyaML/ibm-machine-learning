{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 6, Part e: ARMA DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3ed72d58-7719-40d6-a229-73778f445d4a"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In the previous three lessons, you learned several fundamental time series concepts like stationarity and smoothing. Now we'll build upon that knowledge by digging into yet another important concept called **autocorrelation**.\n",
    "\n",
    "# Learning Outcomes\n",
    "You should walk away from this tutorial with:\n",
    "1. A practical understanding of Autoregressive (AR) models.\n",
    "1. A practical understanding of Moving Average (MA) models.\n",
    "1. A basic understanding of the Autocorrelation Function (ACF).\n",
    "1. A basic understanding of the Partial Autocorrelation Function (PACF).\n",
    "1. Insight into choosing the order *q* of MA models.\n",
    "1. Insight into choosing the order *p* of AR models.\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# os.chdir('data')\n",
    "from colorsetup import colors, palette\n",
    "sns.set_palette(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "150671c3-8e05-4d77-acc2-5dcf82bb601d"
    }
   },
   "source": [
    "One of the key concepts in the quantitative toolbox is that of mean reversion. This process refers to a time series that displays a tendency to revert to its historical mean value. Mathematically, such a (continuous) time series is referred to as an Ornstein-Uhlenbeck process. \n",
    "\n",
    "This is in contrast to a random walk (aka Brownian motion), which has no \"memory\" of where it has been at each particular instance of time. \n",
    "\n",
    "The mean-reverting property of a time series can be exploited in order to produce better predictions.\n",
    "\n",
    "A continuous mean-reverting time series can be represented by an Ornstein-Uhlenbeck stochastic differential equation:\n",
    "\n",
    "$dx_{t} = θ(μ−x_{t})dt + σdW_{t}$\n",
    " \n",
    "Where: \n",
    "- θ is the rate of reversion to the mean, \n",
    "- μ is the mean value of the process, \n",
    "- σ is the variance of the process and \n",
    "- $W_{t}$ is a Wiener Process or Brownian Motion.\n",
    "\n",
    "In a discrete setting the equation states that the change of the price series in the next time period is proportional to the difference between the mean price and the current price, with the addition of Gaussian noise.\n",
    "\n",
    "https://www.quantstart.com/articles/Basics-of-Statistical-Mean-Reversion-Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "81feb119-d24b-45fc-bb19-12a003a78136"
    }
   },
   "source": [
    "## Section 2: ARMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter [Autoregressive Integrated Moving Average (ARIMA)](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) modeling. When we have autocorrelation between outcomes and their ancestors, we will see a theme, or relationship in the outcome plot. This relationship can be modeled in its own way, allowing us to predict the future with a confidence level commensurate to the strength of the relationship and the proximity to known values (prediction weakens the further out we go).\n",
    "\n",
    "- [ARIMA in R](https://www.otexts.org/fpp/8/5)\n",
    "- [Duke ARIMA Guide](https://people.duke.edu/~rnau/411arim2.htm)\n",
    "- [Great explanation on MA in practice](http://stats.stackexchange.com/questions/164824/moving-average-ma-process-numerical-intuition)\n",
    "\n",
    "\n",
    "For second-order stationary (both mean and variance: $\\mu_t = \\mu$ and $\\sigma_t^2 = \\sigma^2$ for all $t$) data, autocovariance is expressed as a function only of the time lag $k$:\n",
    "\n",
    "$$ \\gamma_k = E[(x_t-\\mu)(x_{t+k} - \\mu)] $$\n",
    "  \n",
    "Therefore, the autocorrelation function is defined as:\n",
    "\n",
    "$$ \\rho_k = \\frac{\\gamma_k}{\\sigma^2} $$\n",
    "  \n",
    "We use the plot of these values at different lags to determine optimal ARIMA parameters. Notice how `phi` changes the process.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/ArTimeSeries.svg/685px-ArTimeSeries.svg.png)\n",
    "By Tomaschwutz - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=14740378\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Autoregressive (AR) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autocorrelation:** a variable's correlation with itself at different lags.\n",
    "\n",
    "AR models regress on actual past values \n",
    "\n",
    "This is the first order or **AR(1)** formula you should know: $y_t = \\beta_0 + \\beta_1y_{t-1}+\\epsilon_t$\n",
    "\n",
    "The $\\beta$'s are just like those in linear regression and $\\epsilon$ is irreducible error.\n",
    "\n",
    "A second order or **AR(2)** would look like this: $y_t = \\beta_0 + \\beta_1y_{t-1}+\\beta_2y_{t-2}+\\epsilon_t$\n",
    "\n",
    "The pattern of adding another coefficient and another past term continues to whichever order you choose. Choosing that order called *p* is something we will discuss shortly.\n",
    "\n",
    "In the meantime, let's walk through a basic autocorrelation example. We'll generate our own data to gain insight into how ar models work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# create autocorrelated data\n",
    "time = np.arange(100)\n",
    "#Assuming 0 mean\n",
    "ar1_sample = np.zeros(100)\n",
    "\n",
    "# Set our first number to a random value with expected mean of 0 and standard deviation of 2.5\n",
    "ar1_sample[0] += np.random.normal(loc=0, scale=2.5, size=1)\n",
    "\n",
    "# Set every value thereafter as 0.7 * the last term plus a random error\n",
    "for t in time[1:]:\n",
    "    ar1_sample[t] = (0.7 * ar1_sample[t-1]) + np.random.normal(loc=0, scale=2.5, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2641e5fef20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.fill_between(time,ar1_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create prediction for generated data to show we came up with a model that is approximately ar(1) with phi $\\approx$ 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.714076508251403"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A constant trend was included in the model specification, but the `exog` data already contains a column of constants.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\iliya\\Downloads\\course-1\\time-series-forecasting\\06e_DEMO_ARMA.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/iliya/Downloads/course-1/time-series-forecasting/06e_DEMO_ARMA.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# using ARMA model from statsmodel package\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/iliya/Downloads/course-1/time-series-forecasting/06e_DEMO_ARMA.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mtsa\u001b[39m.\u001b[39;49marima\u001b[39m.\u001b[39;49mARIMA(ar1_sample, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\iliya\\Downloads\\course-1\\venv\\lib\\site-packages\\statsmodels\\tsa\\arima\\model.py:153\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    146\u001b[0m     trend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[39m# Construct the specification\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m# (don't pass specific values of enforce stationarity/invertibility,\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m# because we don't actually want to restrict the estimators based on\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m# this criteria. Instead, we'll just make sure that the parameter\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m# estimates from those methods satisfy the criteria.)\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec_arima \u001b[39m=\u001b[39m SARIMAXSpecification(\n\u001b[0;32m    154\u001b[0m     endog, exog\u001b[39m=\u001b[39;49mexog, order\u001b[39m=\u001b[39;49morder, seasonal_order\u001b[39m=\u001b[39;49mseasonal_order,\n\u001b[0;32m    155\u001b[0m     trend\u001b[39m=\u001b[39;49mtrend, enforce_stationarity\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enforce_invertibility\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    156\u001b[0m     concentrate_scale\u001b[39m=\u001b[39;49mconcentrate_scale, trend_offset\u001b[39m=\u001b[39;49mtrend_offset,\n\u001b[0;32m    157\u001b[0m     dates\u001b[39m=\u001b[39;49mdates, freq\u001b[39m=\u001b[39;49mfreq, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    158\u001b[0m     validate_specification\u001b[39m=\u001b[39;49mvalidate_specification)\n\u001b[0;32m    159\u001b[0m exog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec_arima\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39morig_exog\n\u001b[0;32m    161\u001b[0m \u001b[39m# Raise an error if we have a constant in an integrated model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iliya\\Downloads\\course-1\\venv\\lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py:395\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[39m# If we already have a constant column, raise an error\u001b[39;00m\n\u001b[0;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(col_const):\n\u001b[1;32m--> 395\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA constant trend was included in the model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    396\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39m specification, but the `exog` data already\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    397\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39m contains a column of constants.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[39m# This contains the included exponents of the trend polynomial,\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m# where e.g. the constant term has exponent 0, a linear trend has\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# exponent 1, etc.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend_terms \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend_poly \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: A constant trend was included in the model specification, but the `exog` data already contains a column of constants."
     ]
    }
   ],
   "source": [
    "# using ARMA model from statsmodel package\n",
    "model = sm.tsa.arima.ARIMA(ar1_sample, (1, 1, 1))\n",
    "# model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create autocorrelated data\n",
    "np.random.seed(112)\n",
    "# Mean is again 0\n",
    "ar2_sample = np.zeros(100)\n",
    "# Set first two values to random values with expected mean of 0 and standard deviation of 2.5\n",
    "ar2_sample[0:2] += np.random.normal(loc=0, scale=2.5, size=2)\n",
    "# Set future values as 0.3 times the prior value and 0.3 times value two prior\n",
    "for t in time[2:]:\n",
    "    ar2_sample[t] = (0.3 * ar2_sample[t-1]) + (0.3 * ar2_sample[t-2]) + np.random.normal(loc=0, scale=2.5, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time,ar2_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again running statsmodel ARMA to predict parameters for generated data\n",
    "model = sm.tsa.ARMA(ar2_sample, (2, 0)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is function to help in generating different series\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "\n",
    "arparams = np.array([0.3,0.3])\n",
    "maparams = np.array([0])\n",
    "ar = np.r_[1, -arparams] # add zero-lag and negate, np.r_ is simply making it one array\n",
    "ma = np.r_[1, maparams] # add zero-lag\n",
    "y = arma_generate_sample(ar, ma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again running statsmodel ARMA to predict parameters for generated data\n",
    "model = sm.tsa.ARMA(y, (2, 0)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that outcomes of same model can be very different given random nature of model and fact that this is emant to predict mean reversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Moving Average(MA) models\n",
    "\n",
    "\n",
    "### MA Model Specifics\n",
    "A MA model is defined by this equation: $y_t=c+e_t+θ_1e_{t−1}+θ_2e_{t−2}+⋯+θ_qe_{t−q}$ where $e_t$ is white noise. The value $c$ is a constant value and the $\\theta$'s are coefficients, not unlike those found in linear regression.\n",
    "\n",
    "### MA Models != Moving Average Smoothing\n",
    "An important distinction is that a moving average model is not the same thing as moving average smoothing. What we did in previous lessons was smoothing. It has important properties already discussed. However, we turn our attention to moving average models, which are a completely different beast.\n",
    "\n",
    "Moving average smoothing is useful for estimating trend and seasonality of past data. MA models, on the other hand, are a useful forecasting model that regresses on past forecast errors in order to forecast future values. It is easy to lump the two techniques together, but they serve very different functions. \n",
    "Thus, a moving-average model is conceptually a linear regression of the current value of the series against current and previous (unobserved) white noise error terms or random shocks. The random shocks at each point are assumed to be mutually independent and to come from the same distribution, typically a normal distribution, with location at zero and constant scale.\n",
    "\n",
    "### Interpretation\n",
    "The moving-average model is essentially a finite impulse response filter applied to white noise, with some additional interpretation placed on it. \n",
    "\n",
    "The role of the random shocks in the MA model differs from their role in the autoregressive (AR) model in two ways.\n",
    "- First, they are propagated to future values of the time series directly: for example, \n",
    "$\\varepsilon _{t-1}$ appears directly on the right side of the equation for $X_{t}$. In contrast, in an AR model $\\varepsilon _{t-1}$ does not appear on the right side of the $X_{t}$ equation, but it does appear on the right side of the $X_{t-1}$ equation, and $X_{t-1}$ appears on the right side of the $X_{t}$ equation, giving only an indirect effect of $\\varepsilon _{t-1}$ on $X_{t}$. \n",
    "- Second, in the MA model a shock affects X values only for the current period and q periods into the future; in contrast, in the AR model a shock affects X values infinitely far into the future, because $\\varepsilon _{t}$ affects $X_{t}$, which affects $X_{t+1}$, etc.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Moving-average_model\n",
    "\n",
    "We'll generate our own data so we know the generative process for an MA series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "np.random.seed(12)\n",
    "\n",
    "# create autocorrelated data\n",
    "time = np.arange(100)\n",
    "#mean 0\n",
    "ma1_sample = np.zeros(100)\n",
    "#create vector of random normally distributed errors\n",
    "error = np.random.normal(loc=0, scale=2.5, size=100)\n",
    "# set first value to one of the random errors\n",
    "ma1_sample[0] += error[0]\n",
    "\n",
    "#set future values to 0.4 times error of prior value plus the current error term\n",
    "for t in time[1:]:\n",
    "    ma1_sample[t] = (0.4 * error[t-1]) + error[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time,ma1_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find model params for generated sample \n",
    "model = sm.tsa.ARMA(ma1_sample, (0, 1)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# create autocorrelated data\n",
    "time = np.arange(100)\n",
    "ma2_sample = np.zeros(100)\n",
    "error = np.random.normal(loc=0, scale=2.5, size=100)\n",
    "ma2_sample[0:2] = error[0:2]\n",
    "#regress future values on linear functino of prior two errors plus current error\n",
    "for t in time[2:]:\n",
    "    ma2_sample[t] = (0.4 * error[t-1]) + (-0.4 * error[t-2]) + error[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time,ma2_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find model params for generated sample \n",
    "model = sm.tsa.ARMA(ma2_sample, (0, 2)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is function to help in generating different series\n",
    "np.random.seed(123)\n",
    "arparams = np.array([0])\n",
    "maparams = np.array([0.4,-0.4])\n",
    "ar = np.r_[1, -arparams] # add zero-lag and negate, np.r_ is simply making it one array\n",
    "ma = np.r_[1, maparams] # add zero-lag\n",
    "y = arma_generate_sample(ar, ma, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to show we came up with a model that is approximately ar(1) with phi = 0.7\n",
    "# We will get back to modeling\n",
    "\n",
    "model = sm.tsa.ARMA(y, (0, 2)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a8fc8ecc-2519-407a-973e-28d33ce53b59"
    }
   },
   "source": [
    "Some things to note:\n",
    "1. AR models propagate shocks infinitely\n",
    "1. If a process depends on previous values of itself then it is an AR process. If it depends on previous errors than it is an MA process.\n",
    "1. AR processes will exhibit exponential decay in ACF and a cut-off in PACF\n",
    "\n",
    "### Moving Average Models (This is NOT a Simple/Weighted/Exponential Moving Average)\n",
    "\n",
    "Some things to note:\n",
    "1. MA models do not propagate shocks infinitely; they die after `q` lags\n",
    "1. If a process depends on previous values of itself, then it is an AR process. If it depends on previous errors, then it is an MA process.\n",
    "1. MA processes will exhibit exponential decay in PACF and a cut-off in ACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: The Autocorrelation Function (ACF)\n",
    "There's a crucial question we need to answer: How do you choose the orders (p and q) for a time series\n",
    "\n",
    "In order to answer that question, we need to understand the Autocorrelation Function (ACF). \n",
    "\n",
    "Let's start by showing an example ACF plot for our different simulated series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.tsa.graphics.plot_acf(ar1_sample, lags=range(1,30), alpha=0.05,title = 'ar1 ACF')\n",
    "fig = sm.tsa.graphics.plot_acf(ma1_sample, lags=range(1,15), alpha=0.05,title = 'ma1 ACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanation is in order. First, the blue region represents a confidence interval. Alpha in this case was set to 0.05 (95% confidence interval). This can be set to whatever float value you require. See the **plot_acf** function for details. \n",
    "\n",
    "The stems represent lagged correlation values. In other words, a lag of 1 will show correlation with the prior endogenous value. A lag of 2 shows correlation to the value 2 prior and so on. Remember that we're regressing on past forecast values; that's the correlation we're inspecting here. \n",
    "\n",
    "Correlations outside of the confidence interval are statistically significant whereas the others are not. \n",
    "\n",
    "Note that if lag 1 shows strong autocorrelation, lag 2 will show strong autocorrelation as well since lag 1 is correlated with lag 2 and lag 2 with lag 3. That is why you see the ar1 model having the slowly decaying correlation.\n",
    "\n",
    "If we think about the functions, we note that the autocorrelation will propogate for AR(1) models:\n",
    "\n",
    "- $y_t = \\beta_0 + \\beta_1y_{t-1}+\\epsilon_t$\n",
    "- $y_{t-1} = \\beta_0 + \\beta_1y_{t-2}+\\epsilon_{t-1}$\n",
    "- $y_{t} = \\beta_0 + \\beta_0 + \\beta_1y_{t-2}+\\epsilon_{t-1} +\\epsilon_{t}$\n",
    "\n",
    "The past errors will propogate into the future leading to the slowly decaying plot we just mentioned\n",
    "\n",
    "For MA(1) models: \n",
    "\n",
    "- $y_t = y_t=\\beta_0+θ_1e_{t-1}+\\epsilon_t$\n",
    "\n",
    "Only the prior error has an effect on future errors.\n",
    "\n",
    "So an easy way to identify an ar(1) models or ma(1) model is to look to see if the correlation from one effects the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.tsa.graphics.plot_acf(ar2_sample, lags=range(1,15), alpha=0.05,title = 'ar2 ACF')\n",
    "fig = sm.tsa.graphics.plot_acf(ma2_sample, lags=range(1,15), alpha=0.05,title = 'ma2 ACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar story should hold up for ACF for AR(2) and MA(2). Ideally, the ma(1) would be significant, but with simulated data it will not always be perfect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: The Partial Autocorrelation Function (PACF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the order *p* of the AR model is important. Thankfully, there's a useful plot called the Partial Autocorrelation Function plot that can help us with that task. \n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "fig = sm.tsa.graphics.plot_pacf(ar1_sample, lags=range(1,15), alpha=0.05, title = 'pacf ar1')\n",
    "fig = sm.tsa.graphics.plot_pacf(ma1_sample, lags=range(1,15), alpha=0.05, title = 'pacf ma1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *partial autocorrelation* at lag k is the correlation that results after removing the effect of any correlations due to the terms at shorter lags. \n",
    "\n",
    "This makes choosing AR(1) models much easier.\n",
    "\n",
    "First off, the blue region once again is the 95% confidence interval. \n",
    "\n",
    "The ACF is a way to measure the linear relationship between a current observation and observations at previous time periods. It turns out that often we are really only interested in the relationship between the current observation and a past value determined by a lag value. We often don't care about the relationship of values between the two, so we transform them to obtain the PACF. \n",
    "\n",
    "The PACF is a useful tool for identifying the order of the AR model.\n",
    "\n",
    "For MA(1) model we should see that it slowly decays towards 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.tsa.graphics.plot_pacf(ar2_sample, lags=range(1,15), alpha=0.05, title = 'pacf ar2')\n",
    "fig = sm.tsa.graphics.plot_pacf(ma2_sample, lags=range(1,15), alpha=0.05, title = 'pacf ma2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar story should hold up for PACF for AR(2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "You have been provided two datasets: \n",
    "1. **auto_1.csv**\n",
    "2. **auto_2.csv**\n",
    "\n",
    "Your task is to leverage what you've learned in this and previous courses. \n",
    "\n",
    "More specifically, you will do the following:\n",
    "1. Read in **auto_1.csv** and **auto_2.csv**.\n",
    "2. Create a time variable called **mytime** that starts at 0 and is as long as both datasets.\n",
    "3. Generate fill between plots of auto_1 and auto_2.\n",
    "4. Determine the order of p and q.\n",
    "5. Fit model given chosen p and q. Feel free to play with fit of other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "path_to_file = \"./\"\n",
    "auto_1 = pd.read_csv(path_to_file + \"auto_1.csv\")\n",
    "auto_2 = pd.read_csv(path_to_file + \"auto_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create mytime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time component\n",
    "mytime = np.arange(len(auto_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_1 = auto_1.values.reshape(-1)\n",
    "auto_2 = auto_2.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill between plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(mytime,auto_1,auto_2,alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(mytime,auto_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Determine Order (p & q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = sm.tsa.graphics.plot_acf(auto_1, lags=range(1,15), alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = sm.tsa.graphics.plot_pacf(auto_2, lags=range(1,15), alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For auto_1, order p is clearly 2.\n",
    "\n",
    "For auto_2, looks like order of q is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Estimate parameters of model with given choice of p and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.ARMA(auto_1, (2, 0)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.ARMA(auto_2, (0, 1)).fit(trend='nc', disp=0)\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, we have covered: \n",
    "1. Moving Average (MA) models.\n",
    "2. The Autocorrelation Function (ACF).\n",
    "3. Choosing order *q*.\n",
    "4. Autoregressive (AR) models.\n",
    "5. The Partial Autocorrelation Function (PACF).\n",
    "6. Choosing order *p*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": false,
   "nav_menu": {
    "height": "311px",
    "width": "412px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": false,
   "toc_position": {
    "height": "22px",
    "left": "1105px",
    "right": "20px",
    "top": "-1px",
    "width": "22px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "92293bb34660a29f1a960a53b6e3064c3a168867c83c97fb05fcb559a4836e06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
